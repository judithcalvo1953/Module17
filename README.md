# Module17
This module implements a variety of machine learning algorithms to predict credit risk based on many factors commonly analyzed by lenders.  Because the data is so imbalanced between high and low-risk loans, oversampling of the high risk category, undersampling of the low risk and a combination (SMOTEEN) algorithms are used.  In addition, Random Forest and ADA boost are used to train and test the data. I compare the report metrics from each and then conclude which appears to be the best model.
## Balanced Random Forest Classifier
- The overall accuracy of this model is 0.79, indicative of an acceptable accuracy in prediction.  However, accuracy is not the entire story. The precision for the high-risk loans is only 0.04, while it is 1.00 for low risk.  The recall(sensitivity) for high risk is 0.67. The F1 scores for high risk is only 0.07, and finally the index of balanced accuracy (iba) is nearly the same for both, but is only slightly above pure chance (0.59) for the high risk loans.  In evaluating this model, I'd want to further explore other approaches, to determine if another model would fit better.  Also, when listing the features in descending order, of the plethora of features, only the top 5 seem to contribute anything to prediction of risk, and even these seem to be low (all weights are < 0.10). I would explore the possiblity of overfitting due to so many features that have been included, and would suggest removing most of these to see if we can arrive at a better model.
## ADA Boost Classifier
- This model seems a much better fit.  The overall accuracy is 0.93, indicative of a highly accurate model.  However, this is not the only important metric.  The recall for high risk is 0.94, but the F1 score is low, at 0.16.  Again, however, the precision for high risk is low at only 0.09.  While the reliability/precision for low risk is very high at 1.00, it is only 0.09 for high risk. The recall/sensitivity is high for the low risk class as well, at 0.94.  Finally, the index of balanced accuracy (iba) is high for both classes, at 0.87 for the high risk and 0.87 for the low risk.  I would conclude that this is a better learning model to predict high risk loans than the Balanced Random Forest Classifier.
## Techniques of Oversampling and Undersampling
The second part of the challenge presents several techniques that attempt to correct the sample size imbalance in the two categories, and employ logistic regression to analyze the data and predict high vs. low risk:
- Naive Random Oversampling
- SMOTE Oversampling
- Undersampling with Cluster Centroids
- Undersampling using SMOTEENN
### Naive Random Oversampling
- This model does not perform well overall.  The overall accuracy is 0.65, indicative of a somewhat accurate model.  However, this is not the only important metric.  The recall for high risk is 0.61, but the F1 score is low, at 0.02.  While the reliability/precision for low risk is very high at 1.00, it is only 0.01 for high risk. The recall/sensitivity is somewhat low for the low risk class as well, at 0.61, compared to 0.61 for high risk.  Finally, the index of balanced accuracy (iba) is low for both classes, at 0.42 for the high risk and 0.42 for the low risk.  I would conclude that this is a not a good model to predict high risk loans.
### SMOTE Oversampling
- This model does not perform well overall.  The overall accuracy is 0.66, indicative of a somewhat accurate model and almost the same as the Naive Random Oversampling Model.  However, this is not the only important metric.  The recall for high risk is 0.63 but the F1 score is low, also at 0.02.  While the reliability/precision for low risk is very high at 1.00, it is only 0.01 for high risk. The recall/sensitivity is somewhat better for the low risk class as well, at 0.69, compared to 0.63 for high risk.  Finally, the index of balanced accuracy (iba) is low for both classes, at 0.44 for the high risk and 0.44 for the low risk.  I would conclude that this is a not a good model to predict high risk loans.  While you are quite able to predict low risk, if you are wanting to avoid high risk, possibly defaulting loans, you'd want a model to be more sensitive and precise to high risk cases.
## Cluster Centroids Undersampling
- This model performs worse than the SMOTE model.  The overall accuracy is only 0.53, indicative of a little better than chance at predicting outcomes.  However, this is not the only important metric.  The recall for high risk is 0.66 but the F1 score is low, at 0.01.  While the reliability/precision for low risk is very high at 1.00, it is only 0.01 for high risk. The recall/sensitivity is somewhat worse for the low risk class, at 0.40, compared to 0.66 for high risk.  Finally, the index of balanced accuracy (iba) is low for both classes, at 0.27 for the high risk and 0.26 for the low risk.  I would conclude that this is a not a good model to predict high risk loans. In the case of defaulting, the sensitivity/recall is like casting a conservative wide net to be safe, even though you are likely to get a higher proportion of false positives.  The sensitivity of this model is lower than than the SMOTE model.
## SMOTEENN
- This model performs better than the Cluster Centroids Model, with overall accuracy at 0.65, and is equivalent to the  SMOTE Oversampling (0.65 vs. 0.66 for SMOTE). Again, one must examine several metrics, and in this case, the recall for high risk is 0.71, compared to recall for low risk at 0.58. This is desireable when wanting to cast a wide net and minimize risk. Precision for high risk is very low, at only 0.01 and is very high for low risk at 1.00. Finally, the index of balanced accuracy (iba) is low for both classes, at 0.42 for the high risk and 0.41 for the low risk. 
## Conclusion
-The ADA Boost Classifier seems to be the best machine learning model, in terms of overall accuracy and in index of balanced accuracy (iba). The recall/sensitivity for both classes is high, thus one is likely to better measure how many loans are high risk and correctly defined as high risk. It is better to detect everyone who might default, in order to minimize defaulting loans and lost revenue.  If the goal was to provide loans to individuals with promise and not deny those who would pay on time, then precision would be the better metric to employ.
- In all of these models, I think they may suffer from overfitting, in that many features that do not really contribute to accurate learning and prediction are included.  There is likely a good amount of random noise or error that is being captured. I would want to explore further more parsimonious models, in order to be more confident that the model will generalize to other sets of data (performing well on previously unseen input).

In completing this analysis, I used other resources to assist me in interpretation:
1. "Statistics for Beginners in Data Science", Ahmad Wael, AI Publishing, 2019.
2. "Practical Statistics for Data Scientists, 50 Essential Concepts", Peter Bruce and Andrew Bruce, O'Reilly Publishers, 2017.
